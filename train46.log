nohup: ignoring input
Optimizing /mnt/data/tijaz/trainingOutputs/sec3att0046im1sph1pc1
Output folder: /mnt/data/tijaz/trainingOutputs/sec3att0046im1sph1pc1 [06/09 13:40:49]
Reading camera 1/64Reading camera 2/64Reading camera 3/64Reading camera 4/64Reading camera 5/64Reading camera 6/64Reading camera 7/64Reading camera 8/64Reading camera 9/64Reading camera 10/64Reading camera 11/64Reading camera 12/64Reading camera 13/64Reading camera 14/64Reading camera 15/64Reading camera 16/64Reading camera 17/64Reading camera 18/64Reading camera 19/64Reading camera 20/64Reading camera 21/64Reading camera 22/64Reading camera 23/64Reading camera 24/64Reading camera 25/64Reading camera 26/64Reading camera 27/64Reading camera 28/64Reading camera 29/64Reading camera 30/64Reading camera 31/64Reading camera 32/64Reading camera 33/64Reading camera 34/64Reading camera 35/64Reading camera 36/64Reading camera 37/64Reading camera 38/64Reading camera 39/64Reading camera 40/64Reading camera 41/64Reading camera 42/64Reading camera 43/64Reading camera 44/64Reading camera 45/64Reading camera 46/64Reading camera 47/64Reading camera 48/64Reading camera 49/64Reading camera 50/64Reading camera 51/64Reading camera 52/64Reading camera 53/64Reading camera 54/64Reading camera 55/64Reading camera 56/64Reading camera 57/64Reading camera 58/64Reading camera 59/64Reading camera 60/64Reading camera 61/64Reading camera 62/64Reading camera 63/64Reading camera 64/64 [06/09 13:40:49]
Loading Training Cameras [06/09 13:40:49]
Loading Test Cameras [06/09 13:40:53]
Number of points at initialisation :  245884 [06/09 13:40:53]
Training progress:   0%|          | 0/60000 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/mnt/data/tijaz/gaussian-splatting/train.py", line 301, in <module>
    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)
  File "/mnt/data/tijaz/gaussian-splatting/train.py", line 130, in training
    mahalanobis_squared, mahalanobis_loss = gaussians.compute_mahalanobis_loss()
  File "/mnt/data/tijaz/gaussian-splatting/scene/gaussian_model.py", line 501, in compute_mahalanobis_loss
    diff = current_xyz.unsqueeze(1) - initial_xyz.unsqueeze(0)  # Shape: (N, M, 3)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 675.68 GiB. GPU 0 has a total capacity of 79.25 GiB of which 7.99 GiB is free. Process 2767562 has 67.47 GiB memory in use. Process 1731677 has 3.53 GiB memory in use. Of the allocated memory 2.97 GiB is allocated by PyTorch, and 38.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Training progress:   0%|          | 0/60000 [00:00<?, ?it/s]
