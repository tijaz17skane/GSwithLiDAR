nohup: ignoring input
Optimizing /mnt/data/tijaz/trainingOutputs/sec3att0066im1sph0pc1
Output folder: /mnt/data/tijaz/trainingOutputs/sec3att0066im1sph0pc1 [19/09 18:33:17]
Reading camera 1/32Reading camera 2/32Reading camera 3/32Reading camera 4/32Reading camera 5/32Reading camera 6/32Reading camera 7/32Reading camera 8/32Reading camera 9/32Reading camera 10/32Reading camera 11/32Reading camera 12/32Reading camera 13/32Reading camera 14/32Reading camera 15/32Reading camera 16/32Reading camera 17/32Reading camera 18/32Reading camera 19/32Reading camera 20/32Reading camera 21/32Reading camera 22/32Reading camera 23/32Reading camera 24/32Reading camera 25/32Reading camera 26/32Reading camera 27/32Reading camera 28/32Reading camera 29/32Reading camera 30/32Reading camera 31/32Reading camera 32/32 [19/09 18:33:17]
Loading Training Cameras [19/09 18:33:17]
[ INFO ] Encountered quite large input images (>1.6K pixels width), rescaling to 1.6K.
 If this is not desired, please explicitly specify '--resolution/-r' as 1 [19/09 18:33:17]
Loading Test Cameras [19/09 18:33:20]
Number of points at initialisation :  245884 [19/09 18:33:20]
Training progress:   0%|          | 0/30000 [00:00<?, ?it/s]Training progress:   0%|          | 0/30000 [00:10<?, ?it/s, Loss=0.0515880, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 10/30000 [00:10<8:46:44,  1.05s/it, Loss=0.0515880, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 10/30000 [00:21<8:46:44,  1.05s/it, Loss=0.0461268, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 20/30000 [00:21<8:46:48,  1.05s/it, Loss=0.0461268, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 20/30000 [00:30<8:46:48,  1.05s/it, Loss=0.0519590, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 30/30000 [00:30<8:29:40,  1.02s/it, Loss=0.0519590, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 30/30000 [00:41<8:29:40,  1.02s/it, Loss=0.0520947, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 40/30000 [00:41<8:38:09,  1.04s/it, Loss=0.0520947, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 40/30000 [00:50<8:38:09,  1.04s/it, Loss=0.0432669, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 50/30000 [00:50<8:18:49,  1.00it/s, Loss=0.0432669, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 50/30000 [01:03<8:18:49,  1.00it/s, Loss=0.0527270, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 60/30000 [01:03<8:56:44,  1.08s/it, Loss=0.0527270, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 60/30000 [01:10<8:56:44,  1.08s/it, Loss=0.0518910, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 70/30000 [01:10<8:09:36,  1.02it/s, Loss=0.0518910, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 70/30000 [01:22<8:09:36,  1.02it/s, Loss=0.0526362, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 80/30000 [01:22<8:31:41,  1.03s/it, Loss=0.0526362, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 80/30000 [01:35<8:31:41,  1.03s/it, Loss=0.0506452, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 90/30000 [01:35<9:16:11,  1.12s/it, Loss=0.0506452, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 90/30000 [01:51<9:16:11,  1.12s/it, Loss=0.0504483, Depth Loss=0.0000000, Graph Maha=0.0008077]Training progress:   0%|          | 100/30000 [01:51<10:31:20,  1.27s/it, Loss=0.0504483, Depth Loss=0.0000000, Graph Maha=0.0008077]Training progress:   0%|          | 100/30000 [02:01<10:31:20,  1.27s/it, Loss=0.0457498, Depth Loss=0.0000000, Graph Maha=0.0000049]Training progress:   0%|          | 110/30000 [02:01<9:59:06,  1.20s/it, Loss=0.0457498, Depth Loss=0.0000000, Graph Maha=0.0000049] Training progress:   0%|          | 110/30000 [02:14<9:59:06,  1.20s/it, Loss=0.0534660, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 120/30000 [02:14<10:01:05,  1.21s/it, Loss=0.0534660, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 120/30000 [02:23<10:01:05,  1.21s/it, Loss=0.0514017, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 130/30000 [02:23<9:24:19,  1.13s/it, Loss=0.0514017, Depth Loss=0.0000000, Graph Maha=0.0000000] Training progress:   0%|          | 130/30000 [02:37<9:24:19,  1.13s/it, Loss=0.0481718, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 140/30000 [02:37<9:55:28,  1.20s/it, Loss=0.0481718, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 140/30000 [02:47<9:55:28,  1.20s/it, Loss=0.0522016, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 150/30000 [02:47<9:28:09,  1.14s/it, Loss=0.0522016, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   0%|          | 150/30000 [02:56<9:28:09,  1.14s/it, Loss=0.0454917, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 160/30000 [02:56<9:01:40,  1.09s/it, Loss=0.0454917, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 160/30000 [03:13<9:01:40,  1.09s/it, Loss=0.0517967, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 170/30000 [03:13<10:18:43,  1.24s/it, Loss=0.0517967, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 170/30000 [03:23<10:18:43,  1.24s/it, Loss=0.0467393, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 180/30000 [03:23<9:54:32,  1.20s/it, Loss=0.0467393, Depth Loss=0.0000000, Graph Maha=0.0000000] Training progress:   1%|          | 180/30000 [03:29<9:54:32,  1.20s/it, Loss=0.0509015, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 190/30000 [03:29<8:25:54,  1.02s/it, Loss=0.0509015, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 190/30000 [03:48<8:25:54,  1.02s/it, Loss=0.0502909, Depth Loss=0.0000000, Graph Maha=0.0008335]Training progress:   1%|          | 200/30000 [03:48<10:29:54,  1.27s/it, Loss=0.0502909, Depth Loss=0.0000000, Graph Maha=0.0008335]Training progress:   1%|          | 200/30000 [03:59<10:29:54,  1.27s/it, Loss=0.0525543, Depth Loss=0.0000000, Graph Maha=0.0000050]Training progress:   1%|          | 210/30000 [03:59<10:03:43,  1.22s/it, Loss=0.0525543, Depth Loss=0.0000000, Graph Maha=0.0000050]Training progress:   1%|          | 210/30000 [04:08<10:03:43,  1.22s/it, Loss=0.0494865, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 220/30000 [04:08<9:11:34,  1.11s/it, Loss=0.0494865, Depth Loss=0.0000000, Graph Maha=0.0000000] Training progress:   1%|          | 220/30000 [04:18<9:11:34,  1.11s/it, Loss=0.0518452, Depth Loss=0.0000000, Graph Maha=0.0000000]Training progress:   1%|          | 230/30000 [04:18<8:59:11,  1.09s/it, Loss=0.0518452, Depth Loss=0.0000000, Graph Maha=0.0000000]Traceback (most recent call last):
  File "/mnt/data/tijaz/gaussian-splatting/train.py", line 316, in <module>
    training(lp.extract(args), op.extract(args), pp.extract(args), args.test_iterations, args.save_iterations, args.checkpoint_iterations, args.start_checkpoint, args.debug_from)
  File "/mnt/data/tijaz/gaussian-splatting/train.py", line 120, in training
    render_pkg = render(viewpoint_cam, gaussians, pipe, bg, use_trained_exp=dataset.train_test_exp, separate_sh=SPARSE_ADAM_AVAILABLE)
  File "/mnt/data/tijaz/gaussian-splatting/gaussian_renderer/__init__.py", line 102, in render
    rendered_image, radii, depth_image = rasterizer(
  File "/mnt/data/tijaz/venv39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/mnt/data/tijaz/venv39/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/data/tijaz/venv39/lib/python3.9/site-packages/diff_gaussian_rasterization/__init__.py", line 197, in forward
    return rasterize_gaussians(
  File "/mnt/data/tijaz/venv39/lib/python3.9/site-packages/diff_gaussian_rasterization/__init__.py", line 32, in rasterize_gaussians
    return _RasterizeGaussians.apply(
  File "/mnt/data/tijaz/venv39/lib/python3.9/site-packages/torch/autograd/function.py", line 553, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/mnt/data/tijaz/venv39/lib/python3.9/site-packages/diff_gaussian_rasterization/__init__.py", line 84, in forward
    num_rendered, color, radii, geomBuffer, binningBuffer, imgBuffer, invdepths = _C.rasterize_gaussians(*args)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 31.82 GiB. GPU 0 has a total capacity of 79.25 GiB of which 24.99 GiB is free. Process 3253997 has 54.26 GiB memory in use. Of the allocated memory 1.58 GiB is allocated by PyTorch, and 52.14 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Training progress:   1%|          | 230/30000 [04:22<9:26:16,  1.14s/it, Loss=0.0518452, Depth Loss=0.0000000, Graph Maha=0.0000000]
